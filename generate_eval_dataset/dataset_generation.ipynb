{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3c6c6c0-0edc-467c-a6c2-8113dbf4c99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --quiet langchain-anthropic langchain-neo4j cyVer langchain-google-genai json-repair \"numpy<2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "def56e63-f956-4460-bde1-b1c230c3230e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab36fa35-f5b9-483a-8d3f-93deae83a287",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "from utils import (\n",
    "    _value_sanitize,\n",
    "    extract_json_from_markdown,\n",
    "    sampling_query,\n",
    "    validate_cypher,\n",
    "    process_database,\n",
    "    process_all_examples_with_limit,\n",
    "    convert_datetime\n",
    ")\n",
    "from prompts import (\n",
    "    system_prompt,\n",
    "    simple_system_prompt,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb8a21e-12fe-47b7-9895-6648b42045a5",
   "metadata": {},
   "source": [
    "# Generate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3dfc7f0-86fb-424e-8a41-1a2eb4677dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM selection\n",
    "models = [ChatAnthropic(model='claude-opus-4-20250514'), ChatGoogleGenerativeAI(model=\"gemini-2.5-pro\")]\n",
    "\n",
    "# Database selection (for demo database)\n",
    "db_url = \"neo4j+s://demo.neo4jlabs.com\"\n",
    "databases = [\n",
    "    \"companies\",\n",
    "    \"twitch\", \n",
    "    \"network\",\n",
    "    \"northwind\",\n",
    "    \"ClinicalKnowledgeGraph\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474866e2-b4a9-4b98-962d-11754df7fde1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "claude-opus-4-20250514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing databases:   0%|                                 | 0/5 [00:00<?, ?it/s]\n",
      "Iterations for companies:   0%|                             | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Iterations for companies: 100%|████████████████████| 1/1 [02:36<00:00, 156.98s/it]\u001b[A\n",
      "                                                                                  \u001b[A\n",
      "Iterations for companies:   0%|                             | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Iterations for companies:  33%|██████▋             | 1/3 [03:17<06:34, 197.37s/it]\u001b[A\n",
      "Iterations for companies:  67%|█████████████▎      | 2/3 [06:18<03:07, 187.79s/it]\u001b[A\n",
      "Iterations for companies: 100%|████████████████████| 3/3 [10:52<00:00, 227.13s/it]\u001b[A\n",
      "Processing databases:  20%|████▊                   | 1/5 [13:34<54:17, 814.41s/it]\u001b[A\n",
      "Iterations for twitch:   0%|                                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Iterations for twitch: 100%|███████████████████████| 1/1 [02:26<00:00, 146.25s/it]\u001b[A\n",
      "                                                                                  \u001b[A\n",
      "Iterations for twitch:   0%|                                | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Iterations for twitch:  33%|███████▋               | 1/3 [03:09<06:19, 189.69s/it]\u001b[A\n",
      "Iterations for twitch:  67%|███████████████▎       | 2/3 [06:12<03:05, 185.58s/it]\u001b[A\n",
      "Iterations for twitch: 100%|███████████████████████| 3/3 [36:12<00:00, 922.87s/it]\u001b[A\n",
      "Processing databases:  40%|████████▍            | 2/5 [52:21<1:25:12, 1704.15s/it]\u001b[A\n",
      "Iterations for network:   0%|                               | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Iterations for network: 100%|██████████████████████| 1/1 [02:40<00:00, 160.22s/it]\u001b[A\n",
      "                                                                                  \u001b[A\n",
      "Iterations for network:   0%|                               | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Iterations for network:  33%|███████▎              | 1/3 [04:37<09:15, 277.87s/it]\u001b[A\n",
      "Iterations for network:  67%|██████████████▋       | 2/3 [09:36<04:50, 290.21s/it]\u001b[A\n",
      "Iterations for network: 100%|██████████████████████| 3/3 [12:52<00:00, 247.12s/it]\u001b[A\n",
      "Processing databases:  60%|████████████▌        | 3/5 [1:07:59<45:08, 1354.35s/it]\u001b[A\n",
      "Iterations for northwind:   0%|                             | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Iterations for northwind: 100%|████████████████████| 1/1 [02:15<00:00, 135.06s/it]\u001b[A\n",
      "                                                                                  \u001b[A\n",
      "Iterations for northwind:   0%|                             | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Iterations for northwind:  33%|██████▋             | 1/3 [03:01<06:02, 181.01s/it]\u001b[A\n",
      "Iterations for northwind:  67%|█████████████▎      | 2/3 [05:52<02:55, 175.67s/it]\u001b[A\n",
      "Iterations for northwind: 100%|████████████████████| 3/3 [09:05<00:00, 183.35s/it]\u001b[A\n",
      "Processing databases:  80%|████████████████▊    | 4/5 [1:19:24<18:10, 1090.23s/it]\u001b[A\n",
      "Iterations for ClinicalKnowledgeGraph:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Iterations for ClinicalKnowledgeGraph: 100%|███████| 1/1 [05:50<00:00, 350.89s/it]\u001b[A\n",
      "                                                                                  \u001b[A\n",
      "Iterations for ClinicalKnowledgeGraph:   0%|                | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Iterations for ClinicalKnowledgeGraph:  33%|██▎    | 1/3 [12:09<24:18, 729.12s/it]\u001b[A\n",
      "Iterations for ClinicalKnowledgeGraph:  67%|████▋  | 2/3 [26:45<13:35, 815.63s/it]\u001b[A\n",
      "Iterations for ClinicalKnowledgeGraph: 100%|███████| 3/3 [35:02<00:00, 670.08s/it]\u001b[A\n",
      "Processing databases: 100%|█████████████████████| 5/5 [2:02:17<00:00, 1467.40s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/gemini-2.5-pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing databases:   0%|                                 | 0/5 [00:00<?, ?it/s]\n",
      "Iterations for companies:   0%|                             | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Iterations for companies: 100%|████████████████████| 1/1 [02:36<00:00, 156.71s/it]\u001b[A\n",
      "                                                                                  \u001b[A\n",
      "Iterations for companies:   0%|                             | 0/3 [00:00<?, ?it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "simple_batch_count = 1 # Number of iterations for simple queries\n",
    "multi_batch_count = 3 # Number of iterations complex queries\n",
    "\n",
    "output = []\n",
    "\n",
    "for model in models:\n",
    "    print(model.model)\n",
    "    for credential in tqdm(databases, desc=\"Processing databases\"):\n",
    "        # Simple question\n",
    "        database_records = process_database(\n",
    "            credential, db_url, model, simple_batch_count, simple_system_prompt\n",
    "        )\n",
    "        output.extend(database_records)\n",
    "\n",
    "        database_records = process_database(\n",
    "            credential, db_url, model, multi_batch_count, system_prompt\n",
    "        )\n",
    "        output.extend(database_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6912281c-de2a-46b7-983e-9bd8eea21a73",
   "metadata": {},
   "source": [
    "# Generate text answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d18e3c-875a-4b12-8713-b14545fab33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_model = ChatAnthropic(model='claude-3-5-haiku-latest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfd5b0b-358c-4fda-9c90-72a835f0a7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate text-based answers\n",
    "await process_all_examples_with_limit(output, qa_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c4a539-b6ce-4f52-8964-4ef93a0600dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(output)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7938bb90-115c-4060-ba5e-d1bbbb61e7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"generated_dataset.json\", \"w\") as f:\n",
    "    json.dump(output, f, indent=2, default=convert_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04be728-685a-4a09-88aa-8f05506fc0b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
